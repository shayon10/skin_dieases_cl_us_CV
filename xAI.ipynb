{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_explain.core.grad_cam import GradCAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "train_dir = r\"D:\\university\\cse400(A,B,C)\\Dataset\\datasetM\\train\"\n",
    "test_dir = r\"D:\\university\\cse400(A,B,C)\\Dataset\\datasetM\\test\"\n",
    "\n",
    "# Parameters\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "num_classes = len(os.listdir(train_dir))  # Assuming each subdirectory is a class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25255 images belonging to 16 classes.\n",
      "Found 17547 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Load datasets\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "790/790 [==============================] - 266s 337ms/step - loss: 2.1561 - accuracy: 0.2988 - val_loss: 3.1507 - val_accuracy: 0.1723\n",
      "Epoch 2/200\n",
      "790/790 [==============================] - 270s 341ms/step - loss: 2.1368 - accuracy: 0.3029 - val_loss: 4.0579 - val_accuracy: 0.1734\n",
      "Epoch 3/200\n",
      "790/790 [==============================] - 245s 310ms/step - loss: 2.1245 - accuracy: 0.3083 - val_loss: 3.3656 - val_accuracy: 0.1771\n",
      "Epoch 4/200\n",
      "790/790 [==============================] - 247s 312ms/step - loss: 2.1030 - accuracy: 0.3150 - val_loss: 3.4529 - val_accuracy: 0.1849\n",
      "Epoch 5/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 2.0905 - accuracy: 0.3197 - val_loss: 3.6987 - val_accuracy: 0.1848\n",
      "Epoch 6/200\n",
      "790/790 [==============================] - 244s 309ms/step - loss: 2.0824 - accuracy: 0.3225 - val_loss: 3.1932 - val_accuracy: 0.1829\n",
      "Epoch 7/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 2.0640 - accuracy: 0.3308 - val_loss: 3.8102 - val_accuracy: 0.1831\n",
      "Epoch 8/200\n",
      "790/790 [==============================] - 240s 304ms/step - loss: 2.0561 - accuracy: 0.3321 - val_loss: 3.6447 - val_accuracy: 0.1952\n",
      "Epoch 9/200\n",
      "790/790 [==============================] - 241s 304ms/step - loss: 2.0398 - accuracy: 0.3402 - val_loss: 3.7511 - val_accuracy: 0.2141\n",
      "Epoch 10/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 2.0212 - accuracy: 0.3441 - val_loss: 3.6109 - val_accuracy: 0.2113\n",
      "Epoch 11/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 2.0078 - accuracy: 0.3450 - val_loss: 3.6455 - val_accuracy: 0.2105\n",
      "Epoch 12/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 2.0011 - accuracy: 0.3497 - val_loss: 3.1879 - val_accuracy: 0.2135\n",
      "Epoch 13/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.9951 - accuracy: 0.3526 - val_loss: 3.4354 - val_accuracy: 0.2085\n",
      "Epoch 14/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.9756 - accuracy: 0.3572 - val_loss: 3.6211 - val_accuracy: 0.2133\n",
      "Epoch 15/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.9750 - accuracy: 0.3582 - val_loss: 3.4700 - val_accuracy: 0.2248\n",
      "Epoch 16/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.9629 - accuracy: 0.3649 - val_loss: 3.3338 - val_accuracy: 0.2227\n",
      "Epoch 17/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.9620 - accuracy: 0.3650 - val_loss: 3.6324 - val_accuracy: 0.2144\n",
      "Epoch 18/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.9404 - accuracy: 0.3711 - val_loss: 3.3407 - val_accuracy: 0.2333\n",
      "Epoch 19/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.9374 - accuracy: 0.3729 - val_loss: 3.5272 - val_accuracy: 0.2277\n",
      "Epoch 20/200\n",
      "790/790 [==============================] - 241s 306ms/step - loss: 1.9296 - accuracy: 0.3735 - val_loss: 3.6559 - val_accuracy: 0.2326\n",
      "Epoch 21/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 1.9210 - accuracy: 0.3787 - val_loss: 3.4469 - val_accuracy: 0.2454\n",
      "Epoch 22/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.9182 - accuracy: 0.3817 - val_loss: 3.2438 - val_accuracy: 0.2304\n",
      "Epoch 23/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.8994 - accuracy: 0.3850 - val_loss: 3.2752 - val_accuracy: 0.2344\n",
      "Epoch 24/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.9056 - accuracy: 0.3851 - val_loss: 3.2687 - val_accuracy: 0.2503\n",
      "Epoch 25/200\n",
      "790/790 [==============================] - 240s 304ms/step - loss: 1.8891 - accuracy: 0.3926 - val_loss: 3.4401 - val_accuracy: 0.2427\n",
      "Epoch 26/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.8733 - accuracy: 0.3957 - val_loss: 3.3837 - val_accuracy: 0.2430\n",
      "Epoch 27/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.8837 - accuracy: 0.3927 - val_loss: 3.4952 - val_accuracy: 0.2349\n",
      "Epoch 28/200\n",
      "790/790 [==============================] - 240s 304ms/step - loss: 1.8743 - accuracy: 0.3935 - val_loss: 3.2435 - val_accuracy: 0.2411\n",
      "Epoch 29/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.8610 - accuracy: 0.3978 - val_loss: 3.0086 - val_accuracy: 0.2513\n",
      "Epoch 30/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.8608 - accuracy: 0.4009 - val_loss: 3.1501 - val_accuracy: 0.2456\n",
      "Epoch 31/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.8647 - accuracy: 0.3952 - val_loss: 3.1767 - val_accuracy: 0.2512\n",
      "Epoch 32/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.8535 - accuracy: 0.4017 - val_loss: 3.4441 - val_accuracy: 0.2476\n",
      "Epoch 33/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.8500 - accuracy: 0.4003 - val_loss: 3.2710 - val_accuracy: 0.2411\n",
      "Epoch 34/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.8345 - accuracy: 0.4097 - val_loss: 2.8914 - val_accuracy: 0.2508\n",
      "Epoch 35/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.8359 - accuracy: 0.4084 - val_loss: 3.4300 - val_accuracy: 0.2504\n",
      "Epoch 36/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.8376 - accuracy: 0.4049 - val_loss: 3.5593 - val_accuracy: 0.2460\n",
      "Epoch 37/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.8168 - accuracy: 0.4132 - val_loss: 3.3053 - val_accuracy: 0.2602\n",
      "Epoch 38/200\n",
      "790/790 [==============================] - 240s 304ms/step - loss: 1.8270 - accuracy: 0.4113 - val_loss: 3.4430 - val_accuracy: 0.2601\n",
      "Epoch 39/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.8178 - accuracy: 0.4141 - val_loss: 3.2363 - val_accuracy: 0.2618\n",
      "Epoch 40/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.8114 - accuracy: 0.4160 - val_loss: 3.4362 - val_accuracy: 0.2456\n",
      "Epoch 41/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.8092 - accuracy: 0.4163 - val_loss: 3.3976 - val_accuracy: 0.2545\n",
      "Epoch 42/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.8044 - accuracy: 0.4171 - val_loss: 3.5197 - val_accuracy: 0.2505\n",
      "Epoch 43/200\n",
      "790/790 [==============================] - 241s 306ms/step - loss: 1.7961 - accuracy: 0.4167 - val_loss: 3.4261 - val_accuracy: 0.2580\n",
      "Epoch 44/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.7963 - accuracy: 0.4186 - val_loss: 3.7335 - val_accuracy: 0.2541\n",
      "Epoch 45/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7971 - accuracy: 0.4198 - val_loss: 3.4061 - val_accuracy: 0.2396\n",
      "Epoch 46/200\n",
      "790/790 [==============================] - 240s 304ms/step - loss: 1.8020 - accuracy: 0.4184 - val_loss: 3.4440 - val_accuracy: 0.2659\n",
      "Epoch 47/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7890 - accuracy: 0.4238 - val_loss: 3.5830 - val_accuracy: 0.2660\n",
      "Epoch 48/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7823 - accuracy: 0.4258 - val_loss: 3.0931 - val_accuracy: 0.2613\n",
      "Epoch 49/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.7873 - accuracy: 0.4242 - val_loss: 3.3255 - val_accuracy: 0.2781\n",
      "Epoch 50/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 1.7851 - accuracy: 0.4245 - val_loss: 3.1871 - val_accuracy: 0.2668\n",
      "Epoch 51/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 1.7800 - accuracy: 0.4247 - val_loss: 3.8254 - val_accuracy: 0.2578\n",
      "Epoch 52/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.7686 - accuracy: 0.4301 - val_loss: 3.6069 - val_accuracy: 0.2681\n",
      "Epoch 53/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.7618 - accuracy: 0.4320 - val_loss: 3.3672 - val_accuracy: 0.2749\n",
      "Epoch 54/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7639 - accuracy: 0.4319 - val_loss: 3.7936 - val_accuracy: 0.2679\n",
      "Epoch 55/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.7638 - accuracy: 0.4298 - val_loss: 3.6630 - val_accuracy: 0.2668\n",
      "Epoch 56/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.7544 - accuracy: 0.4316 - val_loss: 3.6137 - val_accuracy: 0.2780\n",
      "Epoch 57/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.7534 - accuracy: 0.4333 - val_loss: 3.7553 - val_accuracy: 0.2720\n",
      "Epoch 58/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7567 - accuracy: 0.4355 - val_loss: 3.4901 - val_accuracy: 0.2691\n",
      "Epoch 59/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.7533 - accuracy: 0.4349 - val_loss: 3.5969 - val_accuracy: 0.2678\n",
      "Epoch 60/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.7441 - accuracy: 0.4380 - val_loss: 3.5659 - val_accuracy: 0.2731\n",
      "Epoch 61/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 1.7430 - accuracy: 0.4344 - val_loss: 3.3762 - val_accuracy: 0.2757\n",
      "Epoch 62/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7556 - accuracy: 0.4314 - val_loss: 3.4455 - val_accuracy: 0.2514\n",
      "Epoch 63/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7357 - accuracy: 0.4371 - val_loss: 3.7329 - val_accuracy: 0.2800\n",
      "Epoch 64/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7377 - accuracy: 0.4392 - val_loss: 3.4238 - val_accuracy: 0.2644\n",
      "Epoch 65/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.7285 - accuracy: 0.4409 - val_loss: 3.6425 - val_accuracy: 0.2781\n",
      "Epoch 66/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7280 - accuracy: 0.4406 - val_loss: 3.2117 - val_accuracy: 0.2679\n",
      "Epoch 67/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7268 - accuracy: 0.4375 - val_loss: 3.3798 - val_accuracy: 0.2713\n",
      "Epoch 68/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.7332 - accuracy: 0.4416 - val_loss: 3.7182 - val_accuracy: 0.2823\n",
      "Epoch 69/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.7286 - accuracy: 0.4402 - val_loss: 3.3797 - val_accuracy: 0.2669\n",
      "Epoch 70/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7311 - accuracy: 0.4402 - val_loss: 3.4716 - val_accuracy: 0.2562\n",
      "Epoch 71/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7182 - accuracy: 0.4458 - val_loss: 4.1021 - val_accuracy: 0.2876\n",
      "Epoch 72/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7198 - accuracy: 0.4447 - val_loss: 3.6909 - val_accuracy: 0.2660\n",
      "Epoch 73/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7145 - accuracy: 0.4450 - val_loss: 3.6749 - val_accuracy: 0.2741\n",
      "Epoch 74/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7179 - accuracy: 0.4477 - val_loss: 3.4222 - val_accuracy: 0.2811\n",
      "Epoch 75/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.7039 - accuracy: 0.4488 - val_loss: 3.7682 - val_accuracy: 0.2653\n",
      "Epoch 76/200\n",
      "790/790 [==============================] - 240s 304ms/step - loss: 1.7120 - accuracy: 0.4495 - val_loss: 3.7258 - val_accuracy: 0.2684\n",
      "Epoch 77/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.6991 - accuracy: 0.4516 - val_loss: 3.3831 - val_accuracy: 0.2826\n",
      "Epoch 78/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.7114 - accuracy: 0.4493 - val_loss: 3.5581 - val_accuracy: 0.2753\n",
      "Epoch 79/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7101 - accuracy: 0.4504 - val_loss: 3.4811 - val_accuracy: 0.2857\n",
      "Epoch 80/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.6980 - accuracy: 0.4581 - val_loss: 3.5679 - val_accuracy: 0.2794\n",
      "Epoch 81/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 1.6972 - accuracy: 0.4533 - val_loss: 3.6788 - val_accuracy: 0.2922\n",
      "Epoch 82/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 1.6999 - accuracy: 0.4504 - val_loss: 3.5628 - val_accuracy: 0.2538\n",
      "Epoch 83/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.6952 - accuracy: 0.4534 - val_loss: 3.3985 - val_accuracy: 0.2663\n",
      "Epoch 84/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.7026 - accuracy: 0.4506 - val_loss: 3.6261 - val_accuracy: 0.2816\n",
      "Epoch 85/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.6816 - accuracy: 0.4561 - val_loss: 3.4439 - val_accuracy: 0.2676\n",
      "Epoch 86/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.6873 - accuracy: 0.4533 - val_loss: 3.7578 - val_accuracy: 0.2835\n",
      "Epoch 87/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.6832 - accuracy: 0.4537 - val_loss: 3.8279 - val_accuracy: 0.2696\n",
      "Epoch 88/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.6796 - accuracy: 0.4600 - val_loss: 3.9373 - val_accuracy: 0.2870\n",
      "Epoch 89/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.6865 - accuracy: 0.4558 - val_loss: 3.7453 - val_accuracy: 0.2922\n",
      "Epoch 90/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.6634 - accuracy: 0.4620 - val_loss: 3.6189 - val_accuracy: 0.2698\n",
      "Epoch 91/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.6770 - accuracy: 0.4586 - val_loss: 3.9657 - val_accuracy: 0.2855\n",
      "Epoch 92/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.6753 - accuracy: 0.4557 - val_loss: 3.6355 - val_accuracy: 0.2770\n",
      "Epoch 93/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.6754 - accuracy: 0.4593 - val_loss: 3.7105 - val_accuracy: 0.2891\n",
      "Epoch 94/200\n",
      "790/790 [==============================] - 244s 309ms/step - loss: 1.6662 - accuracy: 0.4613 - val_loss: 3.3636 - val_accuracy: 0.2587\n",
      "Epoch 95/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.6791 - accuracy: 0.4588 - val_loss: 4.0877 - val_accuracy: 0.2908\n",
      "Epoch 96/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.6800 - accuracy: 0.4601 - val_loss: 3.6368 - val_accuracy: 0.2766\n",
      "Epoch 97/200\n",
      "790/790 [==============================] - 245s 310ms/step - loss: 1.6656 - accuracy: 0.4621 - val_loss: 3.7366 - val_accuracy: 0.2610\n",
      "Epoch 98/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 1.6539 - accuracy: 0.4660 - val_loss: 3.9073 - val_accuracy: 0.2813\n",
      "Epoch 99/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.6683 - accuracy: 0.4601 - val_loss: 3.2881 - val_accuracy: 0.2659\n",
      "Epoch 100/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.6613 - accuracy: 0.4626 - val_loss: 3.6154 - val_accuracy: 0.2906\n",
      "Epoch 101/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.6612 - accuracy: 0.4598 - val_loss: 3.8742 - val_accuracy: 0.2828\n",
      "Epoch 102/200\n",
      "790/790 [==============================] - 243s 308ms/step - loss: 1.6523 - accuracy: 0.4652 - val_loss: 3.5812 - val_accuracy: 0.2751\n",
      "Epoch 103/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.6505 - accuracy: 0.4681 - val_loss: 3.4704 - val_accuracy: 0.2867\n",
      "Epoch 104/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.6517 - accuracy: 0.4659 - val_loss: 3.6656 - val_accuracy: 0.2803\n",
      "Epoch 105/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.6593 - accuracy: 0.4654 - val_loss: 3.4962 - val_accuracy: 0.2872\n",
      "Epoch 106/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.6638 - accuracy: 0.4651 - val_loss: 3.7398 - val_accuracy: 0.2948\n",
      "Epoch 107/200\n",
      "790/790 [==============================] - 243s 307ms/step - loss: 1.6438 - accuracy: 0.4681 - val_loss: 3.4636 - val_accuracy: 0.2828\n",
      "Epoch 108/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.6460 - accuracy: 0.4699 - val_loss: 3.7922 - val_accuracy: 0.2798\n",
      "Epoch 109/200\n",
      "790/790 [==============================] - 244s 308ms/step - loss: 1.6489 - accuracy: 0.4698 - val_loss: 3.8214 - val_accuracy: 0.2758\n",
      "Epoch 110/200\n",
      "790/790 [==============================] - 242s 307ms/step - loss: 1.6642 - accuracy: 0.4645 - val_loss: 3.4076 - val_accuracy: 0.2884\n",
      "Epoch 111/200\n",
      "790/790 [==============================] - 244s 309ms/step - loss: 1.6437 - accuracy: 0.4669 - val_loss: 3.8973 - val_accuracy: 0.2904\n",
      "Epoch 112/200\n",
      "790/790 [==============================] - 246s 311ms/step - loss: 1.6486 - accuracy: 0.4678 - val_loss: 3.6001 - val_accuracy: 0.2890\n",
      "Epoch 113/200\n",
      "790/790 [==============================] - 239s 302ms/step - loss: 1.6336 - accuracy: 0.4678 - val_loss: 3.4287 - val_accuracy: 0.2812\n",
      "Epoch 114/200\n",
      "790/790 [==============================] - 240s 303ms/step - loss: 1.6266 - accuracy: 0.4736 - val_loss: 4.1870 - val_accuracy: 0.2918\n",
      "Epoch 115/200\n",
      "790/790 [==============================] - 239s 302ms/step - loss: 1.6316 - accuracy: 0.4701 - val_loss: 3.7358 - val_accuracy: 0.3063\n",
      "Epoch 116/200\n",
      "790/790 [==============================] - 238s 302ms/step - loss: 1.6381 - accuracy: 0.4689 - val_loss: 3.5182 - val_accuracy: 0.2979\n",
      "Epoch 117/200\n",
      "790/790 [==============================] - 238s 301ms/step - loss: 1.6331 - accuracy: 0.4742 - val_loss: 3.7879 - val_accuracy: 0.2926\n",
      "Epoch 118/200\n",
      "790/790 [==============================] - 239s 303ms/step - loss: 1.6302 - accuracy: 0.4725 - val_loss: 3.3520 - val_accuracy: 0.3043\n",
      "Epoch 119/200\n",
      "790/790 [==============================] - 760s 963ms/step - loss: 1.6321 - accuracy: 0.4703 - val_loss: 3.8188 - val_accuracy: 0.3010\n",
      "Epoch 120/200\n",
      "790/790 [==============================] - 652s 826ms/step - loss: 1.6226 - accuracy: 0.4776 - val_loss: 3.9374 - val_accuracy: 0.2850\n",
      "Epoch 121/200\n",
      "790/790 [==============================] - 612s 773ms/step - loss: 1.6263 - accuracy: 0.4744 - val_loss: 3.5436 - val_accuracy: 0.2971\n",
      "Epoch 122/200\n",
      "790/790 [==============================] - 571s 722ms/step - loss: 1.6250 - accuracy: 0.4755 - val_loss: 3.9851 - val_accuracy: 0.2973\n",
      "Epoch 123/200\n",
      "790/790 [==============================] - 549s 695ms/step - loss: 1.6190 - accuracy: 0.4758 - val_loss: 4.0759 - val_accuracy: 0.2960\n",
      "Epoch 124/200\n",
      "790/790 [==============================] - 562s 711ms/step - loss: 1.6219 - accuracy: 0.4750 - val_loss: 3.6007 - val_accuracy: 0.2946\n",
      "Epoch 125/200\n",
      "790/790 [==============================] - 557s 704ms/step - loss: 1.6161 - accuracy: 0.4780 - val_loss: 3.8612 - val_accuracy: 0.2843\n",
      "Epoch 126/200\n",
      "790/790 [==============================] - 569s 721ms/step - loss: 1.6156 - accuracy: 0.4755 - val_loss: 3.7304 - val_accuracy: 0.2924\n",
      "Epoch 127/200\n",
      "790/790 [==============================] - 620s 784ms/step - loss: 1.6190 - accuracy: 0.4764 - val_loss: 3.5960 - val_accuracy: 0.3055\n",
      "Epoch 128/200\n",
      "790/790 [==============================] - 853s 1s/step - loss: 1.6118 - accuracy: 0.4768 - val_loss: 4.2479 - val_accuracy: 0.2892\n",
      "Epoch 129/200\n",
      "790/790 [==============================] - 840s 1s/step - loss: 1.6147 - accuracy: 0.4794 - val_loss: 3.6926 - val_accuracy: 0.2940\n",
      "Epoch 130/200\n",
      "790/790 [==============================] - 858s 1s/step - loss: 1.6194 - accuracy: 0.4749 - val_loss: 3.8723 - val_accuracy: 0.2883\n",
      "Epoch 131/200\n",
      "790/790 [==============================] - 820s 1s/step - loss: 1.6081 - accuracy: 0.4800 - val_loss: 3.8068 - val_accuracy: 0.2997\n",
      "Epoch 132/200\n",
      "790/790 [==============================] - 797s 1s/step - loss: 1.6123 - accuracy: 0.4776 - val_loss: 3.7230 - val_accuracy: 0.3044\n",
      "Epoch 133/200\n",
      "790/790 [==============================] - 812s 1s/step - loss: 1.6154 - accuracy: 0.4772 - val_loss: 3.4184 - val_accuracy: 0.2956\n",
      "Epoch 134/200\n",
      "790/790 [==============================] - 850s 1s/step - loss: 1.6081 - accuracy: 0.4825 - val_loss: 3.5658 - val_accuracy: 0.2973\n",
      "Epoch 135/200\n",
      "790/790 [==============================] - 1025s 1s/step - loss: 1.6073 - accuracy: 0.4800 - val_loss: 3.8902 - val_accuracy: 0.2936\n",
      "Epoch 136/200\n",
      "790/790 [==============================] - 1312s 2s/step - loss: 1.6167 - accuracy: 0.4772 - val_loss: 3.6844 - val_accuracy: 0.3029\n",
      "Epoch 137/200\n",
      "790/790 [==============================] - 820s 1s/step - loss: 1.6138 - accuracy: 0.4796 - val_loss: 4.0055 - val_accuracy: 0.2989\n",
      "Epoch 138/200\n",
      "790/790 [==============================] - 810s 1s/step - loss: 1.5957 - accuracy: 0.4820 - val_loss: 3.7816 - val_accuracy: 0.2778\n",
      "Epoch 139/200\n",
      "790/790 [==============================] - 844s 1s/step - loss: 1.6034 - accuracy: 0.4820 - val_loss: 3.6646 - val_accuracy: 0.3112\n",
      "Epoch 140/200\n",
      "790/790 [==============================] - 872s 1s/step - loss: 1.6073 - accuracy: 0.4827 - val_loss: 3.8053 - val_accuracy: 0.2937\n",
      "Epoch 141/200\n",
      "790/790 [==============================] - 755s 956ms/step - loss: 1.5911 - accuracy: 0.4853 - val_loss: 3.5726 - val_accuracy: 0.3056\n",
      "Epoch 142/200\n",
      "790/790 [==============================] - 781s 989ms/step - loss: 1.6094 - accuracy: 0.4808 - val_loss: 4.3230 - val_accuracy: 0.2960\n",
      "Epoch 143/200\n",
      "790/790 [==============================] - 864s 1s/step - loss: 1.5959 - accuracy: 0.4850 - val_loss: 4.2217 - val_accuracy: 0.3072\n",
      "Epoch 144/200\n",
      "790/790 [==============================] - 749s 948ms/step - loss: 1.5966 - accuracy: 0.4826 - val_loss: 3.6752 - val_accuracy: 0.3137\n",
      "Epoch 145/200\n",
      "790/790 [==============================] - 777s 984ms/step - loss: 1.5902 - accuracy: 0.4866 - val_loss: 3.4802 - val_accuracy: 0.3020\n",
      "Epoch 146/200\n",
      "790/790 [==============================] - 842s 1s/step - loss: 1.5948 - accuracy: 0.4843 - val_loss: 3.5144 - val_accuracy: 0.3071\n",
      "Epoch 147/200\n",
      "790/790 [==============================] - 900s 1s/step - loss: 1.5765 - accuracy: 0.4913 - val_loss: 3.6789 - val_accuracy: 0.3061\n",
      "Epoch 148/200\n",
      "790/790 [==============================] - 824s 1s/step - loss: 1.5868 - accuracy: 0.4871 - val_loss: 3.7019 - val_accuracy: 0.3018\n",
      "Epoch 149/200\n",
      "790/790 [==============================] - 837s 1s/step - loss: 1.5938 - accuracy: 0.4853 - val_loss: 3.5509 - val_accuracy: 0.3094\n",
      "Epoch 150/200\n",
      "790/790 [==============================] - 833s 1s/step - loss: 1.5840 - accuracy: 0.4901 - val_loss: 3.3818 - val_accuracy: 0.3081\n",
      "Epoch 151/200\n",
      "790/790 [==============================] - 811s 1s/step - loss: 1.5833 - accuracy: 0.4857 - val_loss: 3.5872 - val_accuracy: 0.2966\n",
      "Epoch 152/200\n",
      "790/790 [==============================] - 692s 875ms/step - loss: 1.6056 - accuracy: 0.4835 - val_loss: 3.6429 - val_accuracy: 0.2897\n",
      "Epoch 153/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.5847 - accuracy: 0.4902 - val_loss: 3.6068 - val_accuracy: 0.3113\n",
      "Epoch 154/200\n",
      "790/790 [==============================] - 240s 304ms/step - loss: 1.5864 - accuracy: 0.4885 - val_loss: 3.4086 - val_accuracy: 0.2981\n",
      "Epoch 155/200\n",
      "790/790 [==============================] - 240s 303ms/step - loss: 1.5870 - accuracy: 0.4850 - val_loss: 4.0392 - val_accuracy: 0.3107\n",
      "Epoch 156/200\n",
      "790/790 [==============================] - 242s 306ms/step - loss: 1.5821 - accuracy: 0.4920 - val_loss: 3.3444 - val_accuracy: 0.3002\n",
      "Epoch 157/200\n",
      "790/790 [==============================] - 241s 305ms/step - loss: 1.5783 - accuracy: 0.4907 - val_loss: 3.6735 - val_accuracy: 0.2997\n",
      "Epoch 158/200\n",
      "790/790 [==============================] - 412s 522ms/step - loss: 1.5847 - accuracy: 0.4887 - val_loss: 3.9617 - val_accuracy: 0.3073\n",
      "Epoch 159/200\n",
      "790/790 [==============================] - 802s 1s/step - loss: 1.5787 - accuracy: 0.4912 - val_loss: 3.8570 - val_accuracy: 0.2953\n",
      "Epoch 160/200\n",
      "790/790 [==============================] - 795s 1s/step - loss: 1.5837 - accuracy: 0.4872 - val_loss: 3.7706 - val_accuracy: 0.3140\n",
      "Epoch 161/200\n",
      "790/790 [==============================] - 835s 1s/step - loss: 1.5754 - accuracy: 0.4883 - val_loss: 4.0201 - val_accuracy: 0.3069\n",
      "Epoch 162/200\n",
      "790/790 [==============================] - 806s 1s/step - loss: 1.5755 - accuracy: 0.4905 - val_loss: 4.0065 - val_accuracy: 0.2962\n",
      "Epoch 163/200\n",
      "790/790 [==============================] - 805s 1s/step - loss: 1.5771 - accuracy: 0.4924 - val_loss: 3.4103 - val_accuracy: 0.3061\n",
      "Epoch 164/200\n",
      "790/790 [==============================] - 800s 1s/step - loss: 1.5798 - accuracy: 0.4938 - val_loss: 3.6350 - val_accuracy: 0.3016\n",
      "Epoch 165/200\n",
      "790/790 [==============================] - 811s 1s/step - loss: 1.5597 - accuracy: 0.5001 - val_loss: 3.5700 - val_accuracy: 0.3134\n",
      "Epoch 166/200\n",
      "790/790 [==============================] - 830s 1s/step - loss: 1.5754 - accuracy: 0.4883 - val_loss: 3.7022 - val_accuracy: 0.2962\n",
      "Epoch 167/200\n",
      "790/790 [==============================] - ETA: 0s - loss: 1.5682 - accuracy: 0.4974"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\Ttgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=200,\n",
    "    validation_data=test_data\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 90s 164ms/step - loss: 3.5283 - accuracy: 0.3076\n",
      "Test Accuracy: 0.31\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GradCAM.explain() missing 1 required positional argument: 'class_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Grad-CAM Explanation\u001b[39;00m\n\u001b[0;32m     13\u001b[0m explainer \u001b[38;5;241m=\u001b[39m GradCAM()\n\u001b[1;32m---> 14\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_image_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv2d_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the last convolutional layer\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Visualize the explanation\u001b[39;00m\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(test_image)\n",
      "\u001b[1;31mTypeError\u001b[0m: GradCAM.explain() missing 1 required positional argument: 'class_index'"
     ]
    }
   ],
   "source": [
    "# Load a test image\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Get a batch of test data\n",
    "test_images, test_labels = next(test_data)\n",
    "\n",
    "# Select a single image for Grad-CAM\n",
    "test_image = test_images[0]\n",
    "test_image_array = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Grad-CAM Explanation\n",
    "explainer = GradCAM()\n",
    "explanation = explainer.explain(\n",
    "    validation_data=(test_image_array, None),\n",
    "    model=model,\n",
    "    layer_name='conv2d_2'  # Specify the last convolutional layer\n",
    ")\n",
    "\n",
    "# Visualize the explanation\n",
    "plt.imshow(test_image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(explanation, cmap='jet', alpha=0.6)\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ttgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
